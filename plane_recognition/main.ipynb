{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет состоит из 32 тысяч изображений 20x20 пикселей, 12 тысяч из которых содержат изображение самолета со спутника, а на остальных имеются различные объекты и части самолетов. Датасет представляет собой массив пикселей, каждый из которых представляется в виде точки в трехмерном пространстве RGB. Каждому изображению соответствует число характеризующее класс, к которому оно принадлежит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('planesnet.json')\n",
    "test = df.copy()\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбрасываем ненужные столбцы(data-столбец изображений,labels-столбец класса):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['data', 'labels']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуем данные и переводим в матрицу размерности (32000,20,20,3)\n",
    "\n",
    "Нормализация необходима для корректной работы нейронной сети, так как широкий спектр значений может негативно сказываться на ее работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df.data.apply(my_image.image_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data).reshape((32000, 20, 20, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки класса приводим в приемлемый вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df.labels.apply(lambda x: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на обучающую и тестовую выборку в соотношении 20000:12000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(data[:20000])\n",
    "y_train = labels[:20000].reshape((20000, 1))\n",
    "X_test = np.array(data[20000:])\n",
    "y_test = labels[20000:].reshape((12000, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводим метки классов в бинарный вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "#Присваиваем переменной значение числа классов в данных\n",
    "#В нашем случае 2 состояния: есть самолет или его нет\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2529db4105d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#выбрать формат для модели CNN, наиболее часто используется Sequental:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "#Создаем модель сверточной нейронной сети на Keras:\n",
    "\n",
    "#На этапе проектирования сверточной нейронной сети CNN нам необходимо \n",
    "#выбрать формат для модели CNN, наиболее часто используется Sequental:\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "'''\n",
    "Первый слой нашей модели - это сверточный слой. Он будет принимать входные данные \n",
    "и пропускать их через сверточные фильтры.\n",
    "При реализации этого в Keras, мы должны указать количество каналов (фильтров), \n",
    "которое нам нужно (а это 32), размер фильтра (3 x 3 в нашем случае), \n",
    "форму входа (при создании первого слоя), функцию активации и отступы.\n",
    "Как уже упоминалось, relu является наиболее распространенной функцией активации, \n",
    "а отступы мы определим через padding = 'same', то есть, мы не меняем размер изображения:\n",
    "'''\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(20, 20, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "'''\n",
    "Теперь мы создадим исключающий слой для предотвращения переобучения,\n",
    "который случайным образом устраняет соединения между слоями \n",
    "(0,2 означает, что он отбрасывает 20% существующих соединений):\n",
    "'''\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "'''\n",
    "Также мы можем выполнить пакетную нормализацию. Пакетная нормализация нормализует входные \n",
    "данные, поступающие в следующий слой, гарантируя, что сеть всегда создает \n",
    "функции активации с тем же распределением, которое нам нужно:\n",
    "'''\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "'''\n",
    "Теперь следует еще один сверточный слой, но размер фильтра увеличивается, \n",
    "так что сеть уже может изучать более сложные представления:\n",
    "'''\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "'''\n",
    "А вот и объединяющий слой, который, как обсуждалось ранее, помогает сделать \n",
    "классификатор изображений более корректным, чтобы он мог изучать релевантные шаблоны.\n",
    "Также опишем исключение (Dropout) и пакетную нормализацию:\n",
    "'''\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "'''\n",
    "Необходимое количество объединяющих слоев зависит от выполняемой задачи. \n",
    "Поскольку изображения в нашем наборе уже достаточно малы, мы не будем объединять \n",
    "их более двух раз.Теперь можно повторить эти слои, \n",
    "чтобы дать сети больше представлений для работы:\n",
    "'''\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "'''\n",
    "После того, как мы закончили со сверточными слоями, нам нужно сжать данные, \n",
    "поэтому мы импортировали функцию Flatten выше. Мы также добавим слой исключения снова:\n",
    "'''\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "'''\n",
    "Теперь мы используем импортированную функцию Dense и создаем первый плотно связанный слой.\n",
    "Нам нужно указать количество нейронов в плотном слое. Число нейронов в последующих \n",
    "слоях уменьшается, в конечном итоге приближаясь к тому же числу нейронов, что и классы \n",
    "в наборе данных (в данном случае 2). Ограничение ядра может упорядочить данные \n",
    "в процессе обучения, что также помогает предотвратить переобучение. \n",
    "Вот почему мы импортировали maxnorm ранее.\n",
    "'''\n",
    "\n",
    "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "'''\n",
    "В этом последнем слое мы уравниваем количество классов с числом нейронов, каждый \n",
    "из которых хранит некоторую вероятность того, что рассматриваемое изображение \n",
    "принадлежит его классу. Наконец, функция активации softmax выбирает нейрон с \n",
    "наибольшей вероятностью в качестве своего выходного значения, предполагая, \n",
    "что изображение принадлежит именно этому классу:\n",
    "'''\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "'''\n",
    "Теперь, когда мы разработали модель, которую хотим использовать, остаётся лишь \n",
    "скомпилировать ее. Укажем количество эпох для обучения(эмпирическим путем было \n",
    "подобрано оптимальное количество эпох обучения) , а также оптимизатор, \n",
    "который мы хотим использовать.\n",
    "Оптимизатор - это то, что настроит веса в вашей сети так, чтобы приблизиться \n",
    "к точке с наименьшими потерями. Алгоритм Адама является одним из наиболее \n",
    "часто используемых оптимизаторов, потому что он дает высокую \n",
    "производительность в большинстве задач:\n",
    "'''\n",
    "\n",
    "epochs = 9\n",
    "optimizer = 'Adam'\n",
    "\n",
    "#Теперь скомпилируем модель с выбранными параметрами. Также укажем метрику для оценки.\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "'''\n",
    "Теперь мы приступаем к обучению модели. Для этого нам нужно вызвать функцию fit() \n",
    "для модели и передать выбранные параметры.\n",
    "'''\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=epochs,\n",
    "          batch_size=64)\n",
    "\n",
    "'''\n",
    "Теперь мы можем оценить модель и посмотреть, как она работает. \n",
    "Просто вызовем model.evaluate():\n",
    "'''\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняем  обученную модель, чтобы потом импортировать её при необходимости\n",
    "\n",
    "model.save('plane_recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Опишем метод для более удобного представления результатов распознавания:\n",
    "\n",
    "def prediction(data):\n",
    "    predict = model.predict(data)\n",
    "    predict = np.round(predict)\n",
    "    for input_data in predict:\n",
    "        if input_data[0] == 0 and input_data[1] == 1:\n",
    "            return 'Самолет найден'\n",
    "    return 'Самолет отсутствует'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conturs/3.jpg\n",
      "The original image size is 749 wide x 804 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет отсутствует\n",
      "conturs/10.jpg\n",
      "The original image size is 1127 wide x 789 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/1.jpg\n",
      "The original image size is 1027 wide x 662 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/4.jpg\n",
      "The original image size is 752 wide x 737 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/8.jpg\n",
      "The original image size is 1249 wide x 898 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/2.jpg\n",
      "The original image size is 1022 wide x 663 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/11.jpeg\n",
      "The original image size is 259 wide x 194 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет отсутствует\n",
      "conturs/6.jpg\n",
      "The original image size is 754 wide x 1008 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/7.jpg\n",
      "The original image size is 1252 wide x 946 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n",
      "conturs/5.jpg\n",
      "The original image size is 754 wide x 1030 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет отсутствует\n",
      "conturs/9.jpg\n",
      "The original image size is 1125 wide x 789 high\n",
      "The resized image size is 400 wide x 400 high\n",
      "Самолет найден\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Применяем этот метод для папки ‘conturs’, \n",
    "в которой находится набор снимков спутника с самолетами:\n",
    "'''\n",
    "\n",
    "files = os.listdir('contours')\n",
    "for file in files:\n",
    "    path = os.path.join('contours', file)\n",
    "    print(path)\n",
    "    print(prediction(my_image.search_image(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
